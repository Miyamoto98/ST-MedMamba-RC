# Spatiotemporal-Enhanced MedSAM2-Mamba Framework: Contextual Learning for Multi-Modal MRI-Based Rectal Cancer Staging 项目概览

本项目旨在构建一个**时空增强型MedSAM2-Mamba框架**，通过上下文学习实现多模态MRI图像在直肠癌分期中的高效与精准应用。我们利用了先进的深度学习模型（如 MedSAM2 和 Mamba），并针对直肠癌分期这一特定医学任务进行了深度优化与应用。目前已在约500例直肠癌的私有MRI数据集上完成训练与验证，并计划探索在额外200例数据上进行迁移学习以验证模型的泛化能力。通过对基础模型的适配和增强，我们旨在提供一个高效且准确的诊断辅助工具。

## 核心任务流程

本项目的核心任务是将患者的 3D MRI 影像数据输入我们微调后的模型，经过一系列专门为直肠癌分期任务设计的处理步骤后，输出最终的分期预测结果。其主要流程如下：

1.  **影像数据输入与预处理：**
    *   模型接收 T2W 和 DWI 两种模态的 3D MRI 影像数据。
    *   数据首先会经过预处理（包括归一化、可能的 ROI 分割和尺寸调整），以准备好输入模型。

2.  **2D 特征提取与序列构建（基于基础模型组件）：**
    *   预处理后的 3D 影像会被切分成一系列 2D 切片。
    *   每个 2D 切片会通过一个 **2D Image Encoder**（利用了 MedSAM2 架构中的图像编码器组件）提取其空间特征。
    *   所有切片的特征会被收集并组织成一个**特征序列**，代表了整个 3D 影像的信息。

3.  **时空特征增强与上下文学习（本项目核心模块）：**
    *   提取出的 2D 特征序列会进入我们设计的 **MemoryBlock** 模块，该模块通过**时空注意力机制**捕获序列内部（即原始 3D 影像切片之间）的上下文关系，实现对时空信息的有效融合。
    *   同时，它还会通过交叉注意力机制，将这些特征与模型学习到的**原型记忆库**进行融合，进一步增强特征的语义表达能力，为后续的上下文学习奠定基础。

4.  **Mamba结构驱动的多模态特征融合（本项目核心模块）：**
    *   经过增强的 T2W 和 DWI 两种模态的特征序列，会进入我们设计的 **MambaFusion** 模块。
    *   **MambaFusion 模块利用Mamba结构**对多模态特征进行深度融合，生成一个统一的**融合特征序列**，从而增强MedSAM2模型在直肠癌分期任务中的上下文学习与特征提取能力。

5.  **分类预测（本项目特有模块）：**
    *   最终的融合特征序列会送入 **Classification Head**（分类头）。
    *   分类头通过全连接层等结构，输出直肠癌的分期预测结果（logits）。

## 项目结构 (高层)

*   `train.py`：模型训练的主脚本，负责微调过程。
*   `inference.py`：模型推理的主脚本，用于部署和预测。
*   `model/`：**本项目核心模块**，包含为直肠癌分期任务设计的 `RectalCancerStagingModel`、`MambaFusion`、`MemoryBlock` 等。
*   `utils/`：包含数据预处理等实用工具函数。
*   `sam2/` 和 `efficient_track_anything/`：**原始基础模型的组件**，本项目在此基础上进行微调和功能复用。
*   `checkpoints/`：存储预训练模型和训练检查点。
*   `data/`：示例 NIfTI 数据。

## 入门指南 (假设)

1.  安装所有必需的 Python 包（通常通过 `requirements.txt`）。
2.  设置 `PYTHONPATH` 以包含项目根目录。
3.  运行 `train.py` 进行模型训练。
4.  运行 `inference.py` 使用训练好的模型进行预测。
